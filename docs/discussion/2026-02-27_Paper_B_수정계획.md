# Paper B 수정 계획

> **일시**: 2026-02-27
> **근거**: `2026-02-27_RAG_메타분석_투트랙전략_토론.md`
> **대상**: `paper_b/` 디렉토리 전체
> **원칙**: 기존 설계(3모델 비교, 4 RQ, 100 studies)의 골격은 유지하면서, 토론에서 도출된 인사이트를 통합

---

## 수정의 핵심 방향

### 기존 Paper B vs. 토론 후 Paper B

| 측면 | 기존 (2026-02-25) | 수정 후 |
|------|-------------------|---------|
| **프레이밍** | "LLM-Assisted Data Extraction 정확도 평가" | "언제/어떤 조건에서 LLM 자동화가 효과적인가" — 조건부 가이드라인 |
| **문헌 맥락** | Gartlehner, Jensen 등 SR 추출 연구 중심 | + RAG+메타분석 결합 연구(Ahad 2024), 자동화 메타분석 SR(2025), 투트랙 개념 |
| **RQ2 해석** | Variable type별 정확도 차이 보고 | → **투트랙 전략의 실증적 근거**로 재해석 (텍스트 기반 vs 표 기반 추출 효과성 차이) |
| **RQ4 확장** | Workflow simulation | + "조건부 자동화 가이드라인" 도출 (데이터 유형별 최적 자동화 수준 제안) |
| **차별화** | MASEM-specific + 3모델 + consensus | + **사회과학 최초 실증** + 투트랙 프레이밍 + 조건부 가이드라인 |

---

## 파일별 수정 계획

### 1. README.md — 제목 및 프레이밍 업데이트

**현재 제목**:
> LLM-Assisted Data Extraction for Meta-Analytic Structural Equation Modeling: A Three-Model Comparative Framework with Multi-Model Consensus Validation

**수정 제목 (안)**:
> When Does LLM-Assisted Data Extraction Work? A Conditional Effectiveness Framework for MASEM with Three-Model Comparison and Two-Track Validation

**수정 이유**: "When Does... Work?"가 조건부 가이드라인 논문임을 즉시 전달. 리뷰어가 "또 하나의 LLM 정확도 논문"으로 분류하지 않도록 차별화.

**수정 내용**:
- 제목 변경
- 연구 설계 요약에 "conditional effectiveness" 프레이밍 추가
- 핵심 RQ 목록에 조건부 가이드라인 산출물 명시
- 독자적 기여(Unique Contributions)에 "사회과학 최초 실증" 추가

---

### 2. LITERATURE_REVIEW.md — 선행연구 확장

**추가할 섹션**: `## 1.8` ~ `## 1.11` (기존 1.1-1.7 이후)

#### 1.8 Ahad et al. (2024) — RAG + 메타분석 최초 결합

```
- 제목: Empowering Meta-Analysis: Leveraging Large Language Models for Scientific Synthesis
- 게재: IEEE Xplore (arXiv:2411.10878)
- 내용: RAG + fine-tuned LLM으로 메타분석 초록 자동 생성
- 결과: 87.6% 관련성, 비관련성 4.56% → 1.9%
- 한계: 합성(synthesis) 초점, 효과크기 추출 정확도 미검증, low-resource 환경
- Paper B 시사점: RAG가 메타분석에 적용된 선례이나, 데이터 추출 정확도 평가가 부재 → Paper B가 이 gap을 채움
```

#### 1.9 자동화 메타분석 체계적 리뷰 (2025)

```
- 제목: Transforming Evidence Synthesis: A Systematic Review of the Evolution of Automated Meta-Analysis in the Age of AI
- 출처: arXiv:2504.20113
- 내용: 978편 중 54편 분석 (2006-2024)
- 핵심 발견: 57% 데이터 추출/통계 집중, 17% 합성 단계, end-to-end 2%만
- 의학 67% vs 비의학 33%
- Paper B 시사점: 사회과학 분야 자동화 실증의 부재 확인 → Paper B의 분야 기여 근거
```

#### 1.10 LLM 벤치마크 — 3단계 자동화 가이드라인 (2025)

```
- 제목: What Level of Automation is "Good Enough"?
- 출처: arXiv:2507.15152
- 내용: 3개 LLM의 메타분석 데이터 추출 비교
- 핵심 발견: 높은 precision, 낮은 recall / 커스텀 프롬프트 recall 15% 향상
- 3단계 가이드라인: 데이터 유형별 자동화 수준 차등 적용
- Paper B 시사점: Paper B의 RQ2 (변수 유형별 정확도)와 직접 연결 → 사회과학 맥락 실증 필요
```

#### 1.11 구조화 데이터 추출 벤치마크

```
- 제목: LLMStructBench (2025)
- 출처: arXiv:2602.14743
- 내용: 22개 모델 × 5개 프롬프팅 전략 비교
- 핵심 발견: GPT-4o 91.4% 정확도
- Paper B 시사점: 표 기반 구조화 추출의 벤치마크 기준 제공 → Module B의 정확도 기대치 설정에 활용
```

**Gap Analysis 섹션 수정**: `## 4. Gap Analysis` 테이블에 행 추가

| 한계 | 기존 연구 | Paper B의 대응 |
|------|----------|---------------|
| **Non-social-science** | 의학 67%, 사회과학 미포함 (PRISMA SR 2025) | 교육/HRD 분야 최초 실증 |
| **No conditional guidelines** | 전체 정확도 보고만 | 데이터 유형별 조건부 자동화 가이드라인 도출 |
| **RAG + MA extraction gap** | Ahad (2024)는 합성만 | 추출 정확도를 Gold Standard 대비 정량 비교 |

---

### 3. ANALYSIS_PLAN.md — RQ2, RQ4 강화

#### RQ2 수정: "투트랙 프레이밍" 추가

기존 `### 2.1 Variable Type Classification` 이후에 추가:

```markdown
### 2.1a Two-Track Interpretation

RQ2의 결과는 "투트랙 전략"의 실증적 근거로 재해석 가능:

| Variable Type | 투트랙 매핑 | 자동화 기대 |
|---|---|---|
| **Bibliographic** (A1-A8) | Track 1 적합 — 텍스트 기반 의미론적 검색으로 충분 | High |
| **Statistical** (B1-B12) | Track 2 필요 — 구조화 표 파싱 필수 | Medium-Low |
| **Classificatory** (C1-C6, D1-D4) | Track 1+2 혼합 — 텍스트 맥락 + 구조화 판단 | Medium |

이 분석은 arXiv 2507.15152의 "3단계 자동화 가이드라인"을 사회과학 MASEM 맥락에서 검증하는 역할.
```

#### RQ4 확장: "조건부 가이드라인" 산출물

기존 `### 4.2 Analysis Steps` 이후에 추가:

```markdown
### 4.2a Conditional Automation Guidelines

RQ4의 workflow simulation 결과를 바탕으로, 다음 조건부 가이드라인 도출:

Step 5: Conditional guidelines matrix
  for each variable_type × automation_level:
    recommend: "full auto" / "AI-first + human verify" / "human only"
    based on: accuracy threshold (from RQ1), type effect (from RQ2),
              consensus improvement (from RQ3), time savings (from RQ4)

Output:
  **Table 11**: Conditional Automation Guidelines
    - Rows: Variable types (Bibliographic, Statistical, Classificatory)
    - Columns: Recommended automation level, Expected accuracy, Time savings, Human oversight needed
    - 실무 연구자를 위한 의사결정 매트릭스
```

---

### 4. JOURNAL_STRATEGY.md — 차별화 전략 강화

**RSM 제출 전략 수정**:

기존 Cover letter 핵심 메시지 이후 추가:

```markdown
### RSM 추가 차별화 포인트 (2026-02-27 토론 반영)

1. **분야 최초**: 사회과학/교육 분야에서 LLM 메타분석 데이터 추출의 조건부 효과성을 실증한 최초 연구
   - 근거: PRISMA SR (2025)에서 비의학 분야는 33%에 불과, 사회과학 MASEM 맥락 부재
2. **조건부 가이드라인**: 단순 정확도 보고를 넘어, "언제/어떤 데이터에 자동화를 적용할 것인가"의 실무 가이드라인 제공
   - 근거: arXiv 2507.15152의 3단계 가이드라인을 확장
3. **투트랙 프레이밍**: 텍스트 기반(Module A/C/D) vs 표 기반(Module B) 추출의 효과성 차이를 실증
   - 근거: RAG 분야의 하이브리드 검색 연구(dense vector + BM25)와 연결

### 예상 Reviewer 대응 추가

**예상 질문 5: "RAG와의 관계는? 이 논문은 RAG 논문인가?"**

대응: 본 연구는 RAG 시스템 자체를 개발/평가하는 것이 아닌, LLM 기반 데이터 추출의 조건부 효과성을 평가하는 방법론 논문. 그러나 Discussion에서 향후 RAG 통합 가능성을 논의하며, 본 연구의 변수 유형별 정확도 결과가 RAG 기반 메타분석 파이프라인 설계에 어떤 함의를 주는지 제시. Ahad et al. (2024)의 합성 중심 접근과 본 연구의 추출 중심 접근이 상호보완적임을 논의.
```

---

### 5. DISCUSSION_LOG_KR.md — 토론 기록 추가

기존 `## 향후 논의 사항` 앞에 새로운 결정 추가:

```markdown
### 결정 9: RAG 투트랙 전략과 Paper B의 관계 (2026-02-27)

**문제**: RAG 기반 메타분석 투트랙 전략을 Paper B에 어떻게 통합할 것인가?

**논의 결과**:
- ScholaRAG + Diverga 파이프라인 전체 공개는 복잡성 과다 → 도구 불가지론적 접근
- RAG + 메타분석 기존 시도 존재 (Ahad 2024)하나 추출 정확도 미검증
- 사회과학 분야 실증 부재 확인 (PRISMA SR 2025: 비의학 33%)

**최종 결정**:
1. Paper B 기존 설계(3모델 비교, 4 RQ, 100 studies) 유지
2. 프레이밍을 "조건부 효과성(conditional effectiveness)"으로 강화
3. RQ2의 Variable Type별 분석을 "투트랙 전략의 실증적 근거"로 재해석
4. RQ4에 "조건부 자동화 가이드라인(Table 11)" 산출물 추가
5. 문헌 리뷰에 Ahad(2024), PRISMA SR(2025), arXiv 벤치마크(2025) 추가
6. Discussion에서 RAG 통합 가능성을 future direction으로 논의

### 결정 10: 논문 제목 변경 (2026-02-27)

**문제**: 기존 제목이 "또 하나의 LLM 정확도 논문"으로 분류될 위험

**기존 제목**: LLM-Assisted Data Extraction for MASEM: A Three-Model Comparative Framework with Multi-Model Consensus Validation

**수정 제목 (안)**:
1. "When Does LLM-Assisted Data Extraction Work? A Conditional Effectiveness Framework for MASEM with Three-Model Comparison and Two-Track Validation"
2. "Conditional Effectiveness of LLM-Assisted Data Extraction in MASEM: Variable-Type Differences, Multi-Model Consensus, and Automation Guidelines"
3. 현재 제목 유지 (변경 불필요)

**최종 결정**: [PI 확인 필요]
```

---

### 6. manuscript/Paper_B_LLM_MASEM_Methodology_Draft_v1.0.docx — 초안 수정 가이드

> Note: .docx 파일 직접 수정은 별도 세션에서 진행. 아래는 섹션별 수정 가이드.

#### Introduction 수정

**추가 단락 (기존 "Gap in the literature" 이후)**:

> 핵심 메시지: 기존 LLM 메타분석 자동화 연구는 (1) 의학 분야 편중, (2) 전체 정확도만 보고, (3) 어떤 데이터 유형에서 자동화가 효과적인지 미규명. 본 연구는 "조건부 효과성" 프레이밍으로, 사회과학 MASEM 맥락에서 변수 유형별 자동화 적합도를 밝힌다.

**추가 인용**: Ahad et al. (2024), PRISMA SR (arXiv:2504.20113), arXiv 벤치마크 (2507.15152)

#### Discussion 수정

**추가 섹션: "Toward Two-Track Automation in Meta-Analysis"**

> 핵심 메시지:
> - RQ2 결과(Bibliographic > Classificatory > Statistical)가 투트랙 전략을 지지하는지 논의
> - Track 1 (텍스트 기반): Bibliographic/Classificatory → 높은 자동화 가능
> - Track 2 (표 기반): Statistical → 구조화 파싱 + 인간 검증 필요
> - Ahad et al. (2024)의 합성 접근과 본 연구의 추출 접근이 상호보완적
> - Future work: RAG 기반 의미론적 검색을 스크리닝 단계에 통합하는 후속 연구 제안

**추가 섹션: "Implications for Social Science Meta-Analysts"**

> 핵심 메시지:
> - Table 11 (Conditional Automation Guidelines)의 실무적 활용법
> - "full auto" 가능 변수, "human verify" 필요 변수, "human only" 변수 구분
> - 연구자의 시간/예산 제약에 따른 의사결정 프레임워크

#### Limitations 수정

**추가 limitation**:

> - 본 연구는 RAG 기반 의미론적 검색을 스크리닝 단계에 적용하지 않았으며, LLM 기반 direct extraction만 평가함. 향후 RAG 통합 시 추가적인 정확도 향상이 가능한지는 후속 연구 필요.
> - 임베딩 모델 및 프롬프트의 버전 의존성으로 인한 재현성 한계. PRISMA-trAIce 준수로 최대한 투명성 확보했으나, 모델 업데이트에 따른 결과 변동 가능성 존재.

---

### 7. CODING_PROTOCOL.md — 소규모 수정

**Module B 설명에 주석 추가**:

기존 Module B (Statistical) 테이블 이후:

```markdown
> **투트랙 해석 주석**: Module B의 12개 통계 변수(B1-B12)는 대부분 correlation matrix table에서 추출됨.
> 이는 RAG 문헌에서 "Track 2 (구조화 표 파싱)"에 해당하며, 텍스트 기반 검색(Track 1)으로는
> 정확한 추출이 어려운 영역. Paper B의 RQ2에서 이 차이가 실증적으로 확인될 예정.
```

---

### 8. 신규 파일: prompts/ 디렉토리 참고 메모

**추가 파일**: `paper_b/prompts/README_two_track_context.md`

```markdown
# Two-Track Context for Prompt Design

## 배경
본 프롬프트들은 "투트랙 전략"을 명시적으로 구현하지는 않으나,
모듈별 분리 설계가 사실상 투트랙 접근을 반영함:

- Module A (Bibliographic) + Module C (Construct) + Module D (Moderator)
  → 텍스트 기반 추출 (Track 1 성격)

- Module B (Correlation/Path Coefficients)
  → 표 기반 수치 추출 (Track 2 성격)

## RQ2와의 연결
Module별 AI 정확도를 비교하면, 텍스트 기반 모듈 vs 표 기반 모듈의
자동화 효과성 차이를 실증할 수 있음.

## 향후 확장 가능성
- Module A/C/D에 RAG 의미론적 검색을 전처리로 추가
- Module B에 전용 표 파싱 파이프라인(LLM → JSON → 정형DB) 적용
- 이 확장은 Paper B의 후속 연구로 제안 (Discussion에서 언급)
```

---

## 수정 우선순위

| 순위 | 파일 | 수정 범위 | 난이도 | 영향도 |
|------|------|----------|--------|--------|
| 1 | `LITERATURE_REVIEW.md` | 4개 선행연구 추가 + Gap Analysis 확장 | 낮음 | 높음 |
| 2 | `README.md` | 제목 + 프레이밍 + 기여 업데이트 | 낮음 | 높음 |
| 3 | `ANALYSIS_PLAN.md` | RQ2 투트랙 해석 + RQ4 가이드라인 추가 | 중간 | 높음 |
| 4 | `DISCUSSION_LOG_KR.md` | 결정 9, 10 추가 | 낮음 | 중간 |
| 5 | `JOURNAL_STRATEGY.md` | 차별화 전략 + Reviewer 대응 추가 | 낮음 | 중간 |
| 6 | `manuscript/*.docx` | Intro/Discussion/Limitations 수정 | 높음 | 높음 |
| 7 | `CODING_PROTOCOL.md` | Module B 주석 추가 | 낮음 | 낮음 |
| 8 | `prompts/README_two_track_context.md` | 신규 파일 | 낮음 | 낮음 |

---

## 수정하지 않는 항목 (기존 유지)

| 파일 | 유지 이유 |
|------|----------|
| `SAMPLING_PROTOCOL.md` | 층화추출 설계에 변경 없음 |
| `RESEARCHER_ROLES.md` | 역할 분담에 변경 없음 |
| `TIMELINE.md` | 6주 일정에 변경 없음 (추가 작업량이 미미) |
| `AUDIT_TRAIL_GUIDE.md` | 감사 추적 요구사항에 변경 없음 |
| `CODING_PROTOCOL.md` (Phase 2/3) | 코딩 절차 자체는 변경 없음 |
| `prompts/module_*.md` | 프롬프트 내용은 변경 없음 (투트랙은 해석 레벨의 추가) |
| `checklists/` | PRISMA-trAIce, TRIPOD-LLM 체크리스트 이미 포함 |

---

## 실행 계획

### 즉시 실행 가능 (PI 확인 불필요)
1. `LITERATURE_REVIEW.md` — 선행연구 4건 추가
2. `DISCUSSION_LOG_KR.md` — 결정 9, 10 추가
3. `prompts/README_two_track_context.md` — 신규 생성

### PI 확인 필요
4. `README.md` — 제목 변경 여부 결정
5. `ANALYSIS_PLAN.md` — RQ4 Table 11 추가 여부
6. `JOURNAL_STRATEGY.md` — 차별화 전략 변경

### 추후 실행 (데이터 수집 후)
7. `manuscript/*.docx` — Introduction/Discussion 실제 집필 시 반영
8. `CODING_PROTOCOL.md` — Module B 주석 (코딩 시작 전)
